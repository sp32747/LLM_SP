{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8290e76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "openai_api_key =os.environ.get(\"OPENAI_API_KEY\")\n",
    "print(openai_api_key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119ef1da-117e-4803-a33a-16b289800130",
   "metadata": {},
   "source": [
    "## initiate LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "df05586d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=OpenAI(temperature=0.6)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e762996f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fded66-cdc5-48ca-9d9f-50a206c946ab",
   "metadata": {},
   "source": [
    "## Prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "21f24d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_templt_name=PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template=\"i want to open an {cuisine} restaurant . suggest one name\"\n",
    ")\n",
    "\n",
    "prompt_templt_item_menu=PromptTemplate(\n",
    "    input_variables=['restro_name'],\n",
    "    template=\"\"\"suggest some food items for {restro_name}\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a600d5e-3f1c-4add-b227-40e6ef740f97",
   "metadata": {},
   "source": [
    "# CHAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c2808f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9607f2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "restro_name_chain=LLMChain(llm=llm,prompt=prompt_templt_name) #,verbose=True\n",
    "item_chain=LLMChain(llm=llm,prompt=prompt_templt_item_menu)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c63618c-facc-4711-bc9c-da8060e87d4f",
   "metadata": {},
   "source": [
    "## Simple sequential chain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1cf2c469-d165-4c7c-9225-78265862a443",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a78caf1e-eecf-4c24-818e-309e306f76ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=SimpleSequentialChain(chains=[restro_name_chain,item_chain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d81eb14-1388-4fa7-ac7f-0133b5789f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=chain.invoke('indian')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed282f5-88da-41a9-91f0-256babb7d073",
   "metadata": {},
   "source": [
    "## Sequential chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c461809b-ad28-4c09-a806-96bf83304de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = OpenAI(temperature=0.7)\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables =['cuisine'],\n",
    "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fency name for this.\"\n",
    ")\n",
    "\n",
    "name_chain =LLMChain(llm=llm, prompt=prompt_template_name, output_key=\"restaurant_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9c4e5d2a-f57f-4406-8d58-d80d34854da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.7)\n",
    "\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables = ['restaurant_name'],\n",
    "    template=\"Suggest some menu items for {restaurant_name}.\"\n",
    ")\n",
    "\n",
    "food_items_chain =LLMChain(llm=llm, prompt=prompt_template_items, output_key=\"menu_items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ceb428f1-e56d-4aa8-b94e-77b19cd5cbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2c35da2b-8996-4be3-b2cb-edae2d7b6ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chain = SequentialChain(\n",
    "    chains = [name_chain, food_items_chain],\n",
    "    input_variables = ['cuisine'],\n",
    "    output_variables = ['restaurant_name', \"menu_items\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4385a97d-e374-46ee-ae77-73ccd1c60482",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"cuisine\": \"Indian\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7753e963-6a53-4a7d-b7a5-ba768c93eb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType, initialize_agent , load_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014ef323-6026-4f4a-b320-ef6a62bdef5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=load_tools([\"wikipedia\",\"llm-math\"],llm=llm)\n",
    "agent=initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose = True\n",
    ")\n",
    "\n",
    "agent.run(\"when was elon musk born? what is his in 2024?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d02945a-f83c-435e-bdff-c47d4762e1cb",
   "metadata": {},
   "source": [
    "### Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7a3644-f8a0-4aec-ad97-39ae791f7983",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=llm,prompt=prompt_template_name)\n",
    "name = chain.run(\"Mexican\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f95239-ee00-4796-83df-2afe21cdf617",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = chain.run(\"Indian\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b8aaf9-70dc-46b6-94a2-86860b1bae70",
   "metadata": {},
   "source": [
    "### ConvemrsationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0619bb6e-252b-4dfc-9041-9aba0244951d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template_name, memory=memory)\n",
    "name = chain.run(\"Mexican\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af88f15-2aaf-44ef-9c82-8d64f04172e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = chain.run(\"Arabic\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4b6d97-c2b6-40b3-8d9a-1960e189856a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chain.memory.buffer) ### we can use this transcript in DB for future use , basically chatting app of customer service use this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db11cb8c-8a0f-421f-a482-f94c243fa918",
   "metadata": {},
   "source": [
    "### the above one keeps on incraaesing the memeory , and each time the whole conversation will go to open api , which will charge more , so avoid that will use a window means number of last conversation it can remeber\n",
    "## memory = ConversationBufferWindowMemory(k=1)\n",
    "## which remebers only one last conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfe156d-9de7-408f-9ee7-b56f650d32f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "\n",
    "convo = ConversationChain(llm=OpenAI(temperature=0.7))\n",
    "print(convo.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71531ebe-9d24-49e9-8266-6c6e9df8f114",
   "metadata": {},
   "outputs": [],
   "source": [
    "convo.run(\"Who won the first cricket world cup?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33eaf1b-9a80-4b8b-98bb-eaefad146966",
   "metadata": {},
   "outputs": [],
   "source": [
    "convo.run(\"How much is 5+5?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ed3e4d-8d5c-41d7-b08b-80c2be4d7a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "convo.run(\"Who was the captain ofthe winning team?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204c267e-8bc2-484c-ac5a-27ebb6f2de61",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(convo.memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dbde87-d1dd-4cbb-9b5c-ca5233c719d5",
   "metadata": {},
   "source": [
    "#### ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfdbad7-40de-4b4c-ace2-76858e05af32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "\n",
    "convo = ConversationChain(\n",
    "    llm=OpenAI(temperature=0.7),\n",
    "    memory=memory\n",
    ")\n",
    "convo.run(\"Who won the first cricket world cup?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b1efdc-5fa8-4f9d-9cf3-4634353650ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "convo.run(\"How much is 5+5?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8995858-c865-4fb5-a466-5a057c39de48",
   "metadata": {},
   "outputs": [],
   "source": [
    "convo.run(\"Who was the captain of the winning team?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "95cedf0e-ec05-4172-8ad2-d0908a14d320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6cbb35f9-eff4-407e-9b18-4470dc1b281c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np1=np.array([1,2,3,4,5,6,7,8,9,10,11,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05095af4-137c-4aca-ab5c-3b8b307e65d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np2=np1.reshape(-1,3)\n",
    "np2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f32a2b13-d290-437e-a8e3-77aace921da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np3=np1.reshape(3,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbe0039-109f-4250-9ad1-5a9147f15b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "np3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d0481a-0bea-4bf9-bdf5-6bee12c421bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np4=np1.reshape(1,-1)\n",
    "np4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e3dd2a-211e-4e47-a703-ed5875a516e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np4[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bb2854-a82c-41e9-9570-c27bbbf63adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np4[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036420c5-593d-48a1-9956-69c30eab9bd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
